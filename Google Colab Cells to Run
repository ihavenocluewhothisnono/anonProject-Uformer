First Cell:
!pip install timm einops natsort warmup_scheduler

Second Cell:
!git clone https://github.com/ihavenocluewhothisnono/anonProject-Uformer.git
%cd anonProject-Uformer

Third Cell:
# training the model is done in this cell
!python train/train_denoise.py \
    --arch UformerExtended \
    --gpu 0 \
    --train_dir dataset/colorization_images \
    --val_dir dataset/colorization_images \
    --save_dir checkpoints_color \
    --batch_size 4 \
    --train_ps 128 \
    --nepoch 100 \
    --optimizer adam \
    --lr_initial 1e-4 \
    --dataset Colorization \
    --env grayscale2rgb

Fourth Cell:

from pickle import FALSE
import torch
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from PIL import Image
import os
import torch.nn.functional as F
import math
import skimage.metrics

from model import UformerExtended
from dataset.dataset_colorization import ColorizationDataset

#Configuration
img_size = 128
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
weights_path = "/content/anonProject-Uformer/checkpoints_color/denoising/Colorization/UformerExtendedgrayscale2rgb/models/colorization_epoch_100.pth"
test_dir = "/content/anonProject-Uformer/dataset/colorization_images/"

#load the model
model = UformerExtended(img_size=img_size, in_chans=1, out_chans=3).to(device)
model = torch.nn.DataParallel(model)
checkpoint = torch.load(weights_path, map_location=device, weights_only=False)
model.load_state_dict(checkpoint['state_dict'])
model.eval()

#stores/loads the data
transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor()
])
dataset = ColorizationDataset(root_dir=test_dir, transform=transform)
loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)

def imshow(tensor):
    return tensor.permute(1, 2, 0).detach().cpu().numpy()

def compute_psnr(img1, img2):
    mse = F.mse_loss(img1, img2)
    if mse == 0:
        return float('inf')
    return 20 * math.log10(1.0 / math.sqrt(mse.item()))

def compute_ssim(img1, img2):
    img1_np = imshow(img1)
    img2_np = imshow(img2)
    return skimage.metrics.structural_similarity(img1_np, img2_np, channel_axis=2, data_range=1.0)


# this section is to asses the actual output and see if its valid
psnr_total, ssim_total = 0, 0
num_samples = 0

for gray, rgb, fname, _ in loader:
    gray, rgb = gray.to(device), rgb.to(device)
    with torch.no_grad():
        output = model(gray)

    psnr = compute_psnr(output[0], rgb[0])
    ssim = compute_ssim(output[0], rgb[0])
    psnr_total += psnr
    ssim_total += ssim
    num_samples += 1

    #display a couple of them
    if num_samples <= 2:
        plt.figure(figsize=(12, 4))

        plt.subplot(1, 3, 1)
        plt.title("Grayscale Input")
        plt.imshow(imshow(gray[0]), cmap='gray')
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.title("Predicted Color")
        plt.imshow(imshow(torch.clamp(output[0], 0, 1)))
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.title("Ground Truth RGB")
        plt.imshow(imshow(rgb[0]))
        plt.axis('off')

        plt.suptitle(f"PSNR: {psnr:.2f} dB | SSIM: {ssim:.4f}", fontsize=12)
        plt.tight_layout()
        plt.show()

if num_samples > 0:
    avg_psnr = psnr_total / num_samples
    avg_ssim = ssim_total / num_samples
    print(f"\nAverage PSNR across {num_samples} samples: {avg_psnr:.2f} dB")
    print(f"Average SSIM across {num_samples} samples: {avg_ssim:.4f}")


Fifth Cell:
!pip freeze > requirements.txt
